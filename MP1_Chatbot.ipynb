{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- Securely set your key BEFORE creating the client ---\n",
        "import os, getpass\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"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\").strip()\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()  # reads OPENAI_API_KEY from environment\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgBc55IyAncO",
        "outputId": "a34f6793-d976-4785-8e8b-099ea797ab46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "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··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Colab: run this single cell ---\n",
        "!pip -q install --upgrade openai gradio\n",
        "\n",
        "import os, re\n",
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "# 1) Set your API key (or use Colab \"Secrets\")\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "client = OpenAI()\n",
        "\n",
        "# 2) System persona (ballet teacher)\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a PROFESSIONAL BALLET TEACHER with an elite performance background (former principal & soloist in top international companies). Teach with discipline, precision, and tough love. Stay in character at all times.\n",
        "\n",
        "COMMUNICATION & TONE\n",
        "- Direct, firm, professional. No slang, emojis, or fluff.\n",
        "- Corrections are short and actionable: e.g., “Lift through your center.” “Rotate from the hips, not the knees.”\n",
        "- Praise is rare and understated: e.g., “Good control today.”\n",
        "- If input is vague, ask for specific details before advising.\n",
        "\n",
        "FEEDBACK DISTRIBUTION\n",
        "- More effort/skill → 3–5 precise technical notes (alignment, turnout from hips, port de bras, épaulement, timing, artistry). Push them harder.\n",
        "- Beginners/struggling → 1–2 fundamentals with brief encouragement.\n",
        "- Minimal focus from user → minimal response.\n",
        "\n",
        "CLASSROOM PRIORITIES\n",
        "- Safety & warm-up, clean mechanics (turnout from hips, strong core, controlled landings, precise footwork).\n",
        "- Musicality layered on solid technique.\n",
        "- Professional discipline and respect for classical tradition.\n",
        "\n",
        "EDGE HANDLING\n",
        "- Vague input → ask targeted follow-ups.\n",
        "- Frustration → firm, encouraging realism: “Progress takes time; refine your basics daily.”\n",
        "- Non-ballet topics → redirect to technique.\n",
        "- Safety: never advise forcing turnout from knees or over-stretching.\n",
        "\n",
        "OUTPUT RULES\n",
        "- Prefer 1–3 tight paragraphs OR a bullet list of 3–5 corrections (for advanced).\n",
        "- Always include WHY a correction matters when useful (injury prevention, mechanics, artistry).\n",
        "\"\"\"\n",
        "\n",
        "DEFAULT_MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "def build_user_context(mode, level, terse):\n",
        "    parts = [f\"[Mode: {mode}] [Level: {level}] [Terse corrections: {terse}]\"]\n",
        "    if mode == \"Class simulation\":\n",
        "        parts.append(\"Provide warm-up, short barre and center combos with clear counts, then targeted corrections.\")\n",
        "    if terse:\n",
        "        parts.append(\"Keep responses concise; prefer bullets for corrections when suitable.\")\n",
        "    if level == \"Beginner\":\n",
        "        parts.append(\"Prioritize alignment, turnout from hips, knee-over-toe tracking, core engagement, simple musicality.\")\n",
        "    elif level == \"Intermediate\":\n",
        "        parts.append(\"Emphasize clean pirouette preparation, controlled landings, consistent épaulement, phrasing.\")\n",
        "    else:\n",
        "        parts.append(\"Push for precision, speed, dynamic attack, nuanced épaulement, presentation, stage-ready polish.\")\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "def clean_user_text(s: str) -> str:\n",
        "    # Strip control chars that can upset validators (keeps \\n, \\t)\n",
        "    return re.sub(r\"[^\\x09\\x0A\\x0D\\x20-\\x7E\\u00A0-\\uFFFF]\", \"\", s or \"\")\n",
        "\n",
        "def make_messages(history_messages, mode, level, terse):\n",
        "    \"\"\"\n",
        "    history_messages is a list of dicts like:\n",
        "      [{\"role\": \"user\", \"content\": \"...\"}, {\"role\":\"assistant\",\"content\":\"...\"} ...]\n",
        "    We prepend system prompts and return a full messages list for the API.\n",
        "    \"\"\"\n",
        "    msgs = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"system\", \"content\": build_user_context(mode, level, terse)},\n",
        "        {\"role\": \"system\", \"content\": \"If the user strays off-topic, briefly redirect to ballet technique.\"},\n",
        "    ]\n",
        "    for m in history_messages:\n",
        "        # Ensure each historical message has role/content strings\n",
        "        role = m.get(\"role\", \"\")\n",
        "        content = clean_user_text(m.get(\"content\", \"\"))\n",
        "        if role in (\"user\", \"assistant\") and content:\n",
        "            msgs.append({\"role\": role, \"content\": content})\n",
        "    return msgs\n",
        "\n",
        "def chat_completion(messages, model=DEFAULT_MODEL, temperature=0.4):\n",
        "    # Using Chat Completions for maximum compatibility with \"messages\" format\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "# --- Gradio App ---\n",
        "with gr.Blocks(title=\"Ballet Teacher Chatbot\") as demo:\n",
        "    gr.Markdown(\"# 🩰 Professional Ballet Teacher — Chatbot\\n\"\n",
        "                \"Direct, disciplined coaching from a former principal dancer.\\n\"\n",
        "                \"Tip: Select your level. Press **Enter** to send.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        mode = gr.Radio([\"Q&A\", \"Feedback on my technique\", \"Class simulation\"],\n",
        "                        value=\"Q&A\", label=\"Mode\")\n",
        "        level = gr.Dropdown([\"Beginner\", \"Intermediate\", \"Advanced/Pre-pro\"],\n",
        "                            value=\"Intermediate\", label=\"Your level\")\n",
        "        terse = gr.Checkbox(value=True, label=\"Terse corrections (concise)\")\n",
        "    with gr.Row():\n",
        "        temperature = gr.Slider(0.0, 1.2, value=0.4, step=0.1, label=\"Creativity (temperature)\")\n",
        "        model = gr.Textbox(value=DEFAULT_MODEL, label=\"OpenAI model\", info=\"e.g., gpt-4o-mini\")\n",
        "\n",
        "    # IMPORTANT: type=\"messages\" means history is a list of {\"role\":..., \"content\":...}\n",
        "    chat = gr.Chatbot(type=\"messages\", height=420)\n",
        "\n",
        "    with gr.Row():\n",
        "        user_box = gr.Textbox(placeholder=\"Ask or describe your movement…\", lines=1)\n",
        "        send_btn = gr.Button(\"Send\")\n",
        "\n",
        "    # State holds the full messages history in messages-format\n",
        "    history_state = gr.State([])  # list of dicts: [{\"role\":..., \"content\":...}, ...]\n",
        "\n",
        "    def on_submit(user_text, history_messages, mode, level, terse, temperature, model):\n",
        "        user_text = clean_user_text(user_text)\n",
        "        if not user_text.strip():\n",
        "            return \"\", history_messages, history_messages  # no change\n",
        "\n",
        "        # Append the user's message to history\n",
        "        history_messages = history_messages + [{\"role\": \"user\", \"content\": user_text}]\n",
        "\n",
        "        # Build messages with system prompts + history\n",
        "        msgs = make_messages(history_messages, mode, level, terse)\n",
        "\n",
        "        try:\n",
        "            reply = chat_completion(msgs, model=model, temperature=temperature)\n",
        "        except Exception as e:\n",
        "            reply = f\"API error: {e}\"\n",
        "\n",
        "        # Append assistant reply\n",
        "        history_messages = history_messages + [{\"role\": \"assistant\", \"content\": reply}]\n",
        "\n",
        "        # Update UI: chat uses the same list, textbox clears\n",
        "        return \"\", history_messages, history_messages\n",
        "\n",
        "    # Wire both Enter and Send button\n",
        "    user_box.submit(\n",
        "        on_submit,\n",
        "        inputs=[user_box, history_state, mode, level, terse, temperature, model],\n",
        "        outputs=[user_box, history_state, chat],\n",
        "    )\n",
        "    send_btn.click(\n",
        "        on_submit,\n",
        "        inputs=[user_box, history_state, mode, level, terse, temperature, model],\n",
        "        outputs=[user_box, history_state, chat],\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "oIhhSjEK_qOq",
        "outputId": "c752b157-1a04-4a66-8e25-64e122e587f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a6e6f20f53398ea920.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a6e6f20f53398ea920.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}